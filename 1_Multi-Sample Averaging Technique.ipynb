{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df35717e-19a0-4ff9-8542-2adc45f05a73",
   "metadata": {},
   "source": [
    "# Browser Fingerprinting and Attack on Canvas Fingerprint Defender\n",
    "\n",
    "Group Members:\n",
    "\n",
    "1: User one\n",
    "2: User two\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- Browser Fingerprinting:\n",
    "\n",
    "A tracking technique that collects unique browser/device attributes (user agent, screen resolution, installed fonts, canvas rendering, WebGL, etc.) to create a \"fingerprint\" for user identification. Canvas fingerprinting specifically exploits subtle rendering differences in HTML5 Canvas to track users across sites.\n",
    "\n",
    "- Canvas Fingerprint Defender:\n",
    "\n",
    "Privacy tools like Canvas Defender inject controlled noise into canvas rendering output, generating randomized or altered fingerprints each time to prevent consistent tracking. This breaks the stability required for effective fingerprinting.\n",
    "\n",
    "- Attack Objective:\n",
    "\n",
    "This project attempts to reverse-engineer the original fingerprint by analyzing multiple noisy samples from the same user. The hypothesis is that averaging out the noise across samples can reconstruct the true fingerprint, defeating the defender's protection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf960fc-7f62-4458-890a-c655550adcc6",
   "metadata": {},
   "source": [
    "## 2. Loading the FPStalker Dataset\n",
    "- The FPStalker dataset:\n",
    "\n",
    "FPStalker is a public dataset containing longitudinal browser fingerprints collected from real users. It includes attributes like canvasJSHashed, userAgentHttp, and fontsFlashHashed.\n",
    "\n",
    "- Load it into a Pandas DataFrame.\n",
    "\n",
    "The dataset is stored as an SQL dump split into multiple files. After downloading and merging these files, regex is used to parse the data by extracting INSERT statements into a Pandas DataFrame. \n",
    "\n",
    "- Analyze the dataset structure.\n",
    "\n",
    "Right after downloading the dataset and then loading it into Pandas DataFrame, we preffered to double-check the final file so that we don't have any inconsistecies. As a bonus we created a CSV file to graphically check all the data in proper excel file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a118d4-42e6-4735-8630-b18c2e4b4c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 11:56:34--  https://github.com/Spirals-Team/FPStalker/archive/refs/heads/master.zip\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "connected. to github.com (github.com)|140.82.121.3|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/Spirals-Team/FPStalker/zip/refs/heads/master [following]\n",
      "--2025-03-06 11:56:34--  https://codeload.github.com/Spirals-Team/FPStalker/zip/refs/heads/master\n",
      "140.82.121.9deload.github.com (codeload.github.com)... \n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘master.zip’\n",
      "\n",
      "master.zip              [        <=>         ] 136.48M  3.73MB/s    in 46s     \n",
      "\n",
      "2025-03-06 11:57:21 (2.94 MB/s) - ‘master.zip’ saved [143109792]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading the FPStalker dataset\n",
    "!wget https://github.com/Spirals-Team/FPStalker/archive/refs/heads/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d1076a-4be5-4b2b-8266-c72da1e52b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword 'SCHILY.fflags'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.fflags'\n"
     ]
    }
   ],
   "source": [
    "#Then Unziping the DataSet\n",
    "!unzip -q master.zip -d FPStalker_data\n",
    "\n",
    "# Combineing the split data files into one SQL (as instructed in README of the Github)\n",
    "!tar -xzf FPStalker_data/FPStalker-master/extension1.txt.tar.gz\n",
    "!tar -xzf FPStalker_data/FPStalker-master/extension2.txt.tar.gz\n",
    "!cat extension1.txt extension2.txt > FPStalker_data/tableFingerprints.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48baa11f-2c25-4c78-bbb2-43ff94821f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counter                                    id  \\\n",
      "0       1  f4f25187-82c7-4265-9bf9-71bc8ed1701f   \n",
      "1       3  4d49cfb2-841d-4a04-81cb-7d1b39a507b4   \n",
      "2       4  7ec277be-f8fd-4ea9-ab89-b2f7d4dacaf6   \n",
      "3       6  3ea176b5-6e50-402a-bd8f-adbfb1b30fb6   \n",
      "4      10  10c196fc-2c76-4e4b-b628-4472949c39c3   \n",
      "\n",
      "                                addressHttp         creationDate  \\\n",
      "0  968635a6aa99d94b3a44e361d75ff06ce018dfbf  2015-10-15 14:00:00   \n",
      "1  21e37622bb08c2274bfa286040888a7139dce4d3  2015-10-15 22:00:00   \n",
      "2  81a4e7916c9c86c687b76ad16b3c56034197f467  2015-10-16 00:00:00   \n",
      "3  cf05b3719bc99cc643ff2dd9204d1af6c91477ec  2015-10-16 11:00:00   \n",
      "4  cd7c5f426fe08beea2abdb6c25acf817c61bb7a5  2015-10-16 21:00:00   \n",
      "\n",
      "            updateDate              endDate  \\\n",
      "0  2015-10-16 14:00:00  2015-10-16 19:00:00   \n",
      "1  2015-10-16 14:00:00  2015-10-17 04:00:00   \n",
      "2  2015-10-16 04:00:00  2015-10-16 08:00:00   \n",
      "3                 NULL  2015-10-19 07:00:00   \n",
      "4                 NULL  2015-10-19 07:00:00   \n",
      "\n",
      "                                       userAgentHttp  \\\n",
      "0  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:41.0) G...   \n",
      "1  Mozilla/5.0 (Windows NT 6.3; rv:41.0) Gecko/20...   \n",
      "2  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:41.0) G...   \n",
      "3  Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:41....   \n",
      "4  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n",
      "\n",
      "                                          acceptHttp           hostHttp  \\\n",
      "0  text/html,application/xhtml+xml,application/xm...  amiunique-backend   \n",
      "1  text/html,application/xhtml+xml,application/xm...  amiunique-backend   \n",
      "2  text/html,application/xhtml+xml,application/xm...  amiunique-backend   \n",
      "3  text/html,application/xhtml+xml,application/xm...  amiunique-backend   \n",
      "4  text/html,application/xhtml+xml,application/xm...  amiunique-backend   \n",
      "\n",
      "  connectionHttp  ...                     rendererWebGLJS octaneScore  \\\n",
      "0          close  ...                       Not supported               \n",
      "1          close  ...                       Not supported               \n",
      "2          close  ...                       Not supported               \n",
      "3          close  ...                       Not supported               \n",
      "4          close  ...  Mesa DRI Intel(R) Ivybridge Mobile               \n",
      "\n",
      "  sunspiderTime                           pluginsJSHashed  \\\n",
      "0                049947beebb2dc8f6aea5e2b6f39ceaa45bbef6f   \n",
      "1                4f1a52c593a8b2342fbeb341f11556b230a7d5c4   \n",
      "2                d9e00d402f8709c74c4f33c759ec13c2f146b372   \n",
      "3                ef11084d57aa43092332a6ae6267aa09172b5f8d   \n",
      "4                dddc2f8127159d9bf35ca7ddcc034296e12c9a3f   \n",
      "\n",
      "                             canvasJSHashed  \\\n",
      "0  7d3176108470111c1c95d5536fe69384b57df861   \n",
      "1  28cce2ea8b08e7e9b2040b670a19ee1523ef7322   \n",
      "2  efac52011167f3ba234b410036d50127c0da7903   \n",
      "3  50d985aef42f6e06350c493a5543f13b3fad6917   \n",
      "4  d93fced7b8a48bb0f856c875c0a8a1a81c88f232   \n",
      "\n",
      "                              webGLJsHashed  \\\n",
      "0  ffb50d76566870ed8423ce3721a6465542919a6e   \n",
      "1  ffb50d76566870ed8423ce3721a6465542919a6e   \n",
      "2  8e635455c1c04acc72cc3cb8b3930fa2002922c7   \n",
      "3  b2350ac4340028ed51420da0f18132961ec142d0   \n",
      "4  e356f6a744a1ce6d22ea8edf1cbadc8ced9922a2   \n",
      "\n",
      "                           fontsFlashHashed   osDetailed browserDetailed  \\\n",
      "0  f56f55343975c8d04201f1e87238ee744b1aeeac    Windows 7         Firefox   \n",
      "1  f56f55343975c8d04201f1e87238ee744b1aeeac  Windows 8.1         Firefox   \n",
      "2  86b60c325482f5052f9f8301e10a9f6e7635b156    Windows 7         Firefox   \n",
      "3  6ba315442ba519ecddd15476a48ab72d9c613add                                \n",
      "4  49bc6f431ed4575824a74328340e5d883988057d                                \n",
      "\n",
      "  browserVersion  \n",
      "0                 \n",
      "1                 \n",
      "2                 \n",
      "3                 \n",
      "4                 \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Reading the SQL dump file\n",
    "file_path = \"FPStalker_data/tableFingerprints.sql\"\n",
    "data = []\n",
    "columns = []\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        # Extract column names from the first INSERT statement\n",
    "        if \"INSERT INTO\" in line and not columns:\n",
    "            column_match = re.search(r\"INSERT INTO `\\w+`\\s*\\((.*?)\\)\\s*VALUES\", line)\n",
    "            if column_match:\n",
    "                columns = [col.strip(\" `\") for col in column_match.group(1).split(\",\")]\n",
    "\n",
    "        # Extract values from INSERT INTO statements\n",
    "        values = re.findall(r\"\\((.*?)\\),\", line)\n",
    "        for value in values:\n",
    "            # Use regex to split while handling quoted strings correctly\n",
    "            row = re.split(r\",(?=(?:[^']*'[^']*')*[^']*$)\", value)\n",
    "            row = [val.strip(\" '\") if val.upper() != \"NULL\" else None for val in row]  # Clean up values\n",
    "\n",
    "            # Ensure row matches the number of columns (handle malformed cases)\n",
    "            if len(row) == len(columns):\n",
    "                data.append(row)\n",
    "\n",
    "# Convert to DataFrame using extracted column names\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# **Fix: Remove potential duplicate column names in first row**\n",
    "if df.iloc[0].tolist() == columns:\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# **Ensure correct column types**\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# Show first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV for debugging\n",
    "#df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "#print(\"Data cleaned and saved to 'cleaned_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16dcc3a-8d7c-40ec-8393-22caeda5ba39",
   "metadata": {},
   "source": [
    "## 3. Detecting Noise in the Dataset\n",
    "- Identify inconsistencies in fingerprints:\n",
    "\n",
    "Inconsistency detection is performed by identifying BrowserIDs that have multiple canvasJSHashed values, which indicates intentional noise injection; for example, 247 browsers exhibited varying hashes.\n",
    "\n",
    "- Check if browserID has multiple different canvasJSHashed values:\n",
    "\n",
    "The methodology involves grouping fingerprints by their id and counting the unique canvasJSHashed entries, where a count greater than one signifies the presence of noise. This high variability confirms that the defender is actively injecting noise, although it also provides multiple samples that could be exploited for noise-averaging attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be161c1a-b3c7-4cb5-9fa5-162d4fe29b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        id  unique_canvas_hashes\n",
      "3     00ce2756-a6dd-4b6b-8ca6-4a7faf307335                     2\n",
      "8     01d2403b-1115-4498-b12b-c26cfcb3e869                     2\n",
      "11    0270f61a-2c1c-4603-9dba-950e1c4bc7da                     2\n",
      "16    02fd491b-74a2-4614-a91b-edd89fd5176c                     2\n",
      "18    03482a40-dded-4b32-9d4f-a3a802126936                     2\n",
      "...                                    ...                   ...\n",
      "1370  f8c53f6a-367e-48e9-99bf-c681ccc1106c                     2\n",
      "1372  f9508a08-908d-4127-80ff-259fd51304ad                     2\n",
      "1393  fd026db8-dad8-4f55-8016-d469844b2862                     2\n",
      "1403  fff6a12d-aab1-4669-9a2e-c369bc300485                     2\n",
      "1404  fff9db58-c20e-4f2c-b07d-9937b70a1273                     2\n",
      "\n",
      "[247 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Counting unique canvas hashes per browserID\n",
    "fingerprint_variability = df.groupby(\"id\")[\"canvasJSHashed\"].nunique().reset_index()\n",
    "fingerprint_variability.columns = [\"id\", \"unique_canvas_hashes\"]\n",
    "\n",
    "# Show cases where canvas hashes vary for the same browserID\n",
    "noisy_browsers = fingerprint_variability[fingerprint_variability[\"unique_canvas_hashes\"] > 1]\n",
    "\n",
    "# Printing the first few rows to check the output\n",
    "print(noisy_browsers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7f829-5df7-4d49-9c07-4e794935138e",
   "metadata": {},
   "source": [
    "## 4. Implementing the Attack\n",
    "- Multi-sample averaging to restore original fingerprint:\n",
    "\n",
    "The multi-sample averaging process involves converting hexadecimal hashes to integers, computing their mean, and then converting the average back to hexadecimal. This approach assumes that the noise introduced around the true fingerprint is symmetrically distributed. \n",
    "\n",
    "- Evaluate results:\n",
    "\n",
    "The method yielded a 0% success rate because hex hashes function as categorical data rather than numerical values, and the defender's noise may be non-linear—for instance, through random bit flips. As a result, averaging these values distorted the true fingerprint instead of neutralizing the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d073f1-f613-4ff4-b8e6-3e7ec0544580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  \\\n",
      "0  0062535e-d9ab-4cb0-ae8f-79133b440129   \n",
      "1  00ce2756-a6dd-4b6b-8ca6-4a7faf307335   \n",
      "2  0143636f-2f9e-45bc-b1f1-13b94a4245ce   \n",
      "3  018ab6d2-9c65-459c-b7fe-4c4e641b13ba   \n",
      "4  01d2403b-1115-4498-b12b-c26cfcb3e869   \n",
      "\n",
      "                   recovered_canvasJSHashed  \n",
      "0  7be7a9cb410b0800000000000000000000000000  \n",
      "1  4e6ce7704287b800000000000000000000000000  \n",
      "2  7d31761084701000000000000000000000000000  \n",
      "3  a248bd3cead2f800000000000000000000000000  \n",
      "4  8f3920c9818ca800000000000000000000000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Grouping fingerprints by browserID\n",
    "grouped_fingerprints = df.groupby(\"id\")[\"canvasJSHashed\"].apply(list).to_dict()\n",
    "\n",
    "# Function to \"average\" hashes (simplified)\n",
    "def average_hash(hashes):\n",
    "    \"\"\"Simulates noise removal by averaging hash values.\"\"\"\n",
    "    # Convert hashes to numerical values for processing\n",
    "    hash_nums = [int(h, 16) for h in hashes if h is not None]  # Ensure valid hex conversion\n",
    "    avg_hash = int(np.mean(hash_nums)) if hash_nums else 0  # Take average safely\n",
    "    return format(avg_hash, 'x')  # Convert back to hex\n",
    "\n",
    "# Apply averaging to noisy browsers\n",
    "recovered_fingerprints = {\n",
    "    browser_id: average_hash(hashes) for browser_id, hashes in grouped_fingerprints.items() if len(hashes) > 1\n",
    "}\n",
    "\n",
    "# Convert results into DataFrame\n",
    "recovered_df = pd.DataFrame(recovered_fingerprints.items(), columns=[\"id\", \"recovered_canvasJSHashed\"])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Save the recovered fingerprints DataFrame to a CSV file for inspection\n",
    "recovered_df.to_csv(\"recovered_fingerprints.csv\", index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(recovered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94943e-c71d-43ac-a8d3-ac15a7ce1674",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "- Summarize findings:\n",
    "\n",
    "The findings reveal that the attack failed to recover the original fingerprints, underscoring the limitations of the averaging approach. \n",
    "\n",
    "- Discuss implications for privacy:\n",
    "\n",
    "Future work should explore alternative noise-removal strategies to enhance the extraction of reliable fingerprints. For instance, one could identify the most frequent hash value to serve as the representative fingerprint or use entropy analysis to detect stable bits within the noisy hashes. These methods may help better isolate the true fingerprint from the intentionally injected noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece048a3-62ae-4763-bdd3-874cb9d60ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.00% of fingerprints recovered correctly\n"
     ]
    }
   ],
   "source": [
    "# Merge recovered fingerprints with original dataset\n",
    "merged_df = df.merge(recovered_df, on=\"id\", how=\"left\")\n",
    "\n",
    "# Ensure both columns are strings and handle NaN values\n",
    "merged_df[\"recovered_canvasJSHashed\"] = merged_df[\"recovered_canvasJSHashed\"].fillna(\"\").astype(str)\n",
    "merged_df[\"canvasJSHashed\"] = merged_df[\"canvasJSHashed\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Check if the recovered hash matches any of the original hashes\n",
    "merged_df[\"match\"] = merged_df.apply(lambda row: row[\"recovered_canvasJSHashed\"] == row[\"canvasJSHashed\"], axis=1)\n",
    "\n",
    "# Calculate success rate\n",
    "success_rate = merged_df[\"match\"].mean()\n",
    "print(f\"Success rate: {success_rate:.2%} of fingerprints recovered correctly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
